{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "03cd2618a86d57bdf1e13ac9fea40245a5e8eaf90cdbb6415b3fe95ffa9984c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Science Project - Detecting Fraudulent Credit Card Transactions\n",
    "\n",
    "The research question here is to investigate whether we can determine a credit card transation to be fraudulent, using the Credit Card Fraud Detection dataset from Kaggle.\n",
    "\n",
    "First we need to import necessary libraries and load in the data. Then do some early exploratory data analysis to better understand the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 199364 entries, 0 to 199363\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    199364 non-null  float64\n 1   V1      199364 non-null  float64\n 2   V2      199364 non-null  float64\n 3   V3      199364 non-null  float64\n 4   V4      199364 non-null  float64\n 5   V5      199364 non-null  float64\n 6   V6      199364 non-null  float64\n 7   V7      199364 non-null  float64\n 8   V8      199364 non-null  float64\n 9   V9      199364 non-null  float64\n 10  V10     199364 non-null  float64\n 11  V11     199364 non-null  float64\n 12  V12     199364 non-null  float64\n 13  V13     199364 non-null  float64\n 14  V14     199364 non-null  float64\n 15  V15     199364 non-null  float64\n 16  V16     199364 non-null  float64\n 17  V17     199364 non-null  float64\n 18  V18     199364 non-null  float64\n 19  V19     199364 non-null  float64\n 20  V20     199364 non-null  float64\n 21  V21     199364 non-null  float64\n 22  V22     199364 non-null  float64\n 23  V23     199364 non-null  float64\n 24  V24     199364 non-null  float64\n 25  V25     199364 non-null  float64\n 26  V26     199364 non-null  float64\n 27  V27     199364 non-null  float64\n 28  V28     199364 non-null  float64\n 29  Amount  199364 non-null  float64\n 30  Class   199364 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 47.2 MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 85443 entries, 0 to 85442\nData columns (total 31 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Time    85443 non-null  float64\n 1   V1      85443 non-null  float64\n 2   V2      85443 non-null  float64\n 3   V3      85443 non-null  float64\n 4   V4      85443 non-null  float64\n 5   V5      85443 non-null  float64\n 6   V6      85443 non-null  float64\n 7   V7      85443 non-null  float64\n 8   V8      85443 non-null  float64\n 9   V9      85443 non-null  float64\n 10  V10     85443 non-null  float64\n 11  V11     85443 non-null  float64\n 12  V12     85443 non-null  float64\n 13  V13     85443 non-null  float64\n 14  V14     85443 non-null  float64\n 15  V15     85443 non-null  float64\n 16  V16     85443 non-null  float64\n 17  V17     85443 non-null  float64\n 18  V18     85443 non-null  float64\n 19  V19     85443 non-null  float64\n 20  V20     85443 non-null  float64\n 21  V21     85443 non-null  float64\n 22  V22     85443 non-null  float64\n 23  V23     85443 non-null  float64\n 24  V24     85443 non-null  float64\n 25  V25     85443 non-null  float64\n 26  V26     85443 non-null  float64\n 27  V27     85443 non-null  float64\n 28  V28     85443 non-null  float64\n 29  Amount  85443 non-null  float64\n 30  Class   85443 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 20.2 MB\nNone\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   33419.0 -2.178201 -3.132187  1.315758 -0.129783 -2.736013  0.743459   \n",
       "1  151317.0  2.064423  0.185575 -1.684612  0.411066  0.479555 -0.797963   \n",
       "2  132434.0 -0.547505  0.798072 -0.719939 -1.129561  0.925708  0.763338   \n",
       "3   81787.0 -0.945710  0.323579  0.595681 -1.288095  0.818906 -0.748491   \n",
       "4  125062.0  1.898722 -0.321038 -1.771837  0.672408  0.115019 -1.267347   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -0.752718 -2.650826 -0.184284  ... -0.828762 -0.219136 -1.004913  0.788588   \n",
       "1  0.205544 -0.240568  0.415454  ... -0.351331 -0.876025  0.343288  0.522189   \n",
       "2  0.231338  0.799204 -0.277812  ...  0.366664  1.068933 -0.101523 -1.604148   \n",
       "3  0.890076 -0.130671 -0.471365  ... -0.371528 -1.149510  0.217859 -0.507989   \n",
       "4  0.612810 -0.441070  0.450298  ...  0.015111  0.006269 -0.029094 -0.071333   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  1.061994 -0.319407 -0.132313  0.333476  937.75      0  \n",
       "1 -0.259568  0.173623 -0.056280 -0.029665    1.98      0  \n",
       "2 -0.318277  0.838076  0.012324 -0.015564   11.95      0  \n",
       "3 -0.026857  0.591496 -0.326179 -0.007543   24.98      0  \n",
       "4  0.179444  0.378225 -0.106042 -0.059506  104.36      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33419.0</td>\n      <td>-2.178201</td>\n      <td>-3.132187</td>\n      <td>1.315758</td>\n      <td>-0.129783</td>\n      <td>-2.736013</td>\n      <td>0.743459</td>\n      <td>-0.752718</td>\n      <td>-2.650826</td>\n      <td>-0.184284</td>\n      <td>...</td>\n      <td>-0.828762</td>\n      <td>-0.219136</td>\n      <td>-1.004913</td>\n      <td>0.788588</td>\n      <td>1.061994</td>\n      <td>-0.319407</td>\n      <td>-0.132313</td>\n      <td>0.333476</td>\n      <td>937.75</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>151317.0</td>\n      <td>2.064423</td>\n      <td>0.185575</td>\n      <td>-1.684612</td>\n      <td>0.411066</td>\n      <td>0.479555</td>\n      <td>-0.797963</td>\n      <td>0.205544</td>\n      <td>-0.240568</td>\n      <td>0.415454</td>\n      <td>...</td>\n      <td>-0.351331</td>\n      <td>-0.876025</td>\n      <td>0.343288</td>\n      <td>0.522189</td>\n      <td>-0.259568</td>\n      <td>0.173623</td>\n      <td>-0.056280</td>\n      <td>-0.029665</td>\n      <td>1.98</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>132434.0</td>\n      <td>-0.547505</td>\n      <td>0.798072</td>\n      <td>-0.719939</td>\n      <td>-1.129561</td>\n      <td>0.925708</td>\n      <td>0.763338</td>\n      <td>0.231338</td>\n      <td>0.799204</td>\n      <td>-0.277812</td>\n      <td>...</td>\n      <td>0.366664</td>\n      <td>1.068933</td>\n      <td>-0.101523</td>\n      <td>-1.604148</td>\n      <td>-0.318277</td>\n      <td>0.838076</td>\n      <td>0.012324</td>\n      <td>-0.015564</td>\n      <td>11.95</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81787.0</td>\n      <td>-0.945710</td>\n      <td>0.323579</td>\n      <td>0.595681</td>\n      <td>-1.288095</td>\n      <td>0.818906</td>\n      <td>-0.748491</td>\n      <td>0.890076</td>\n      <td>-0.130671</td>\n      <td>-0.471365</td>\n      <td>...</td>\n      <td>-0.371528</td>\n      <td>-1.149510</td>\n      <td>0.217859</td>\n      <td>-0.507989</td>\n      <td>-0.026857</td>\n      <td>0.591496</td>\n      <td>-0.326179</td>\n      <td>-0.007543</td>\n      <td>24.98</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>125062.0</td>\n      <td>1.898722</td>\n      <td>-0.321038</td>\n      <td>-1.771837</td>\n      <td>0.672408</td>\n      <td>0.115019</td>\n      <td>-1.267347</td>\n      <td>0.612810</td>\n      <td>-0.441070</td>\n      <td>0.450298</td>\n      <td>...</td>\n      <td>0.015111</td>\n      <td>0.006269</td>\n      <td>-0.029094</td>\n      <td>-0.071333</td>\n      <td>0.179444</td>\n      <td>0.378225</td>\n      <td>-0.106042</td>\n      <td>-0.059506</td>\n      <td>104.36</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\"\"\" Identify whether a credit card transaction is fraudulent or not. Using credit card transaction data from Kaggle \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Load the test and training data\n",
    "train_raw_df = pd.read_csv(\".\\Data\\creditcard_train.csv\")\n",
    "test_raw_df = pd.read_csv(\".\\Data\\creditcard_test.csv\")\n",
    "\n",
    "# See how many rows and columns there are\n",
    "train_raw_df.shape\n",
    "test_raw_df.shape\n",
    "\n",
    "# Look for null values and make sure data types are matching\n",
    "print(train_raw_df.info())\n",
    "print(test_raw_df.info())\n",
    "\n",
    "# Get a brief visual look at the actual values in the data and make some initial deductions\n",
    "train_raw_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "First inspection seems to show that we are dealing with numerical data in our 30 features, and a categorical label in our 'Class' column with just two classes \"1\" and \"0\". \n",
    "\n",
    "There are fortunately no null or missing values in either training or test set.\n",
    "\n",
    "We can also see that features 'V1 - V28' might already been feature scaled in some way, where as 'Time' and 'Amount' have not. Let's use .describe() on every column to check this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_raw_df:\n",
    "    print(train_raw_df[column].describe(), \"\\n\")"
   ]
  },
  {
   "source": [
    "The prints from above confirm these initial thoughts, because the mean for all of the columns from 'V1' to 'V28' are extremely close to zero, suggesting that the data has been standardized (z-score normalised). \n",
    "\n",
    "It therefore makes sense to use this same type of normalisation on the non-feature scaled features, 'Time' and 'Amount' but only when we are using ML models to classify the data. \n",
    "\n",
    "In the meantime, let us continue with further exploratory data analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train duplicates: 585\n",
      "Test duplicates: 131\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "152621      26.0 -0.529912  0.873892  1.347247  0.145457  0.414209  0.100223   \n",
       "162734      74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "188909     145.0 -2.419486  1.949346  0.552998  0.982710 -0.284815  2.411200   \n",
       "114880     919.0  0.904289 -0.538055  0.396058  0.500680 -0.864473 -0.657199   \n",
       "116200     919.0  1.207596 -0.036860  0.572104  0.373148 -0.709633 -0.713698   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "171037  170731.0  2.033492  0.766969 -2.107555  3.631952  1.348594 -0.499907   \n",
       "120908  171288.0  1.912550 -0.455240 -1.750654  0.454324  2.089130  4.160019   \n",
       "168708  171627.0 -1.464380  1.368119  0.815992 -0.601282 -0.689115 -0.487154   \n",
       "149684  172233.0 -2.691642  3.123168 -3.339407  1.017018 -0.293095 -0.167054   \n",
       "136120  172233.0 -2.667936  3.160505 -3.355984  1.007845 -0.377397 -0.109730   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "152621  0.711206  0.176066 -0.286717  ...  0.046949  0.208105 -0.185548   \n",
       "162734 -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "188909 -1.398537 -0.188922  0.675695  ...  1.213390 -1.238354  0.007191   \n",
       "114880  0.027231 -0.029473  0.265447  ... -0.099460 -0.597579 -0.048666   \n",
       "116200 -0.181105  0.011277  0.283940  ... -0.194591 -0.514717  0.089714   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "171037  0.945159 -0.286392 -1.370581  ...  0.241894  0.658545 -0.102644   \n",
       "120908 -0.881302  1.081750  1.022928  ... -0.524067 -1.337510  0.473943   \n",
       "168708 -0.303778  0.884953  0.054065  ...  0.287217  0.947825 -0.218773   \n",
       "149684 -0.745886  2.325616 -1.634651  ...  0.402639  0.259746 -0.086606   \n",
       "136120 -0.667233  2.309700 -1.639306  ...  0.391483  0.266536 -0.079853   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "152621  0.001031  0.098816 -0.552904 -0.073288  0.023307    6.14      0  \n",
       "162734 -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "188909 -1.724175  0.239721 -0.313607 -0.187431  0.119472    6.74      0  \n",
       "114880  0.551824  0.182934  0.402176 -0.081357  0.027252  158.00      0  \n",
       "116200  0.543768  0.240581  0.418921 -0.051693 -0.000085    1.00      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "171037  0.580535  0.643637  0.347240 -0.116618 -0.078601    0.76      0  \n",
       "120908  0.616683 -0.283548 -1.084843  0.073133 -0.036020   11.99      0  \n",
       "168708  0.082926  0.044127  0.639270  0.213565  0.119251    6.82      0  \n",
       "149684 -0.097597  0.083693 -0.453584 -1.205466 -0.213020   36.74      0  \n",
       "136120 -0.096395  0.086719 -0.451128 -1.183743 -0.222200   55.66      0  \n",
       "\n",
       "[585 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>152621</th>\n      <td>26.0</td>\n      <td>-0.529912</td>\n      <td>0.873892</td>\n      <td>1.347247</td>\n      <td>0.145457</td>\n      <td>0.414209</td>\n      <td>0.100223</td>\n      <td>0.711206</td>\n      <td>0.176066</td>\n      <td>-0.286717</td>\n      <td>...</td>\n      <td>0.046949</td>\n      <td>0.208105</td>\n      <td>-0.185548</td>\n      <td>0.001031</td>\n      <td>0.098816</td>\n      <td>-0.552904</td>\n      <td>-0.073288</td>\n      <td>0.023307</td>\n      <td>6.14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>162734</th>\n      <td>74.0</td>\n      <td>1.038370</td>\n      <td>0.127486</td>\n      <td>0.184456</td>\n      <td>1.109950</td>\n      <td>0.441699</td>\n      <td>0.945283</td>\n      <td>-0.036715</td>\n      <td>0.350995</td>\n      <td>0.118950</td>\n      <td>...</td>\n      <td>0.102520</td>\n      <td>0.605089</td>\n      <td>0.023092</td>\n      <td>-0.626463</td>\n      <td>0.479120</td>\n      <td>-0.166937</td>\n      <td>0.081247</td>\n      <td>0.001192</td>\n      <td>1.18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>188909</th>\n      <td>145.0</td>\n      <td>-2.419486</td>\n      <td>1.949346</td>\n      <td>0.552998</td>\n      <td>0.982710</td>\n      <td>-0.284815</td>\n      <td>2.411200</td>\n      <td>-1.398537</td>\n      <td>-0.188922</td>\n      <td>0.675695</td>\n      <td>...</td>\n      <td>1.213390</td>\n      <td>-1.238354</td>\n      <td>0.007191</td>\n      <td>-1.724175</td>\n      <td>0.239721</td>\n      <td>-0.313607</td>\n      <td>-0.187431</td>\n      <td>0.119472</td>\n      <td>6.74</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>114880</th>\n      <td>919.0</td>\n      <td>0.904289</td>\n      <td>-0.538055</td>\n      <td>0.396058</td>\n      <td>0.500680</td>\n      <td>-0.864473</td>\n      <td>-0.657199</td>\n      <td>0.027231</td>\n      <td>-0.029473</td>\n      <td>0.265447</td>\n      <td>...</td>\n      <td>-0.099460</td>\n      <td>-0.597579</td>\n      <td>-0.048666</td>\n      <td>0.551824</td>\n      <td>0.182934</td>\n      <td>0.402176</td>\n      <td>-0.081357</td>\n      <td>0.027252</td>\n      <td>158.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>116200</th>\n      <td>919.0</td>\n      <td>1.207596</td>\n      <td>-0.036860</td>\n      <td>0.572104</td>\n      <td>0.373148</td>\n      <td>-0.709633</td>\n      <td>-0.713698</td>\n      <td>-0.181105</td>\n      <td>0.011277</td>\n      <td>0.283940</td>\n      <td>...</td>\n      <td>-0.194591</td>\n      <td>-0.514717</td>\n      <td>0.089714</td>\n      <td>0.543768</td>\n      <td>0.240581</td>\n      <td>0.418921</td>\n      <td>-0.051693</td>\n      <td>-0.000085</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>171037</th>\n      <td>170731.0</td>\n      <td>2.033492</td>\n      <td>0.766969</td>\n      <td>-2.107555</td>\n      <td>3.631952</td>\n      <td>1.348594</td>\n      <td>-0.499907</td>\n      <td>0.945159</td>\n      <td>-0.286392</td>\n      <td>-1.370581</td>\n      <td>...</td>\n      <td>0.241894</td>\n      <td>0.658545</td>\n      <td>-0.102644</td>\n      <td>0.580535</td>\n      <td>0.643637</td>\n      <td>0.347240</td>\n      <td>-0.116618</td>\n      <td>-0.078601</td>\n      <td>0.76</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>120908</th>\n      <td>171288.0</td>\n      <td>1.912550</td>\n      <td>-0.455240</td>\n      <td>-1.750654</td>\n      <td>0.454324</td>\n      <td>2.089130</td>\n      <td>4.160019</td>\n      <td>-0.881302</td>\n      <td>1.081750</td>\n      <td>1.022928</td>\n      <td>...</td>\n      <td>-0.524067</td>\n      <td>-1.337510</td>\n      <td>0.473943</td>\n      <td>0.616683</td>\n      <td>-0.283548</td>\n      <td>-1.084843</td>\n      <td>0.073133</td>\n      <td>-0.036020</td>\n      <td>11.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>168708</th>\n      <td>171627.0</td>\n      <td>-1.464380</td>\n      <td>1.368119</td>\n      <td>0.815992</td>\n      <td>-0.601282</td>\n      <td>-0.689115</td>\n      <td>-0.487154</td>\n      <td>-0.303778</td>\n      <td>0.884953</td>\n      <td>0.054065</td>\n      <td>...</td>\n      <td>0.287217</td>\n      <td>0.947825</td>\n      <td>-0.218773</td>\n      <td>0.082926</td>\n      <td>0.044127</td>\n      <td>0.639270</td>\n      <td>0.213565</td>\n      <td>0.119251</td>\n      <td>6.82</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149684</th>\n      <td>172233.0</td>\n      <td>-2.691642</td>\n      <td>3.123168</td>\n      <td>-3.339407</td>\n      <td>1.017018</td>\n      <td>-0.293095</td>\n      <td>-0.167054</td>\n      <td>-0.745886</td>\n      <td>2.325616</td>\n      <td>-1.634651</td>\n      <td>...</td>\n      <td>0.402639</td>\n      <td>0.259746</td>\n      <td>-0.086606</td>\n      <td>-0.097597</td>\n      <td>0.083693</td>\n      <td>-0.453584</td>\n      <td>-1.205466</td>\n      <td>-0.213020</td>\n      <td>36.74</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>136120</th>\n      <td>172233.0</td>\n      <td>-2.667936</td>\n      <td>3.160505</td>\n      <td>-3.355984</td>\n      <td>1.007845</td>\n      <td>-0.377397</td>\n      <td>-0.109730</td>\n      <td>-0.667233</td>\n      <td>2.309700</td>\n      <td>-1.639306</td>\n      <td>...</td>\n      <td>0.391483</td>\n      <td>0.266536</td>\n      <td>-0.079853</td>\n      <td>-0.096395</td>\n      <td>0.086719</td>\n      <td>-0.451128</td>\n      <td>-1.183743</td>\n      <td>-0.222200</td>\n      <td>55.66</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>585 rows Ã— 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Look for duplicate values\n",
    "print(\"Train duplicates:\", train_raw_df.duplicated().sum())\n",
    "print(\"Test duplicates:\", test_raw_df.duplicated().sum())\n",
    "\n",
    "train_duplicates = train_raw_df[train_raw_df.duplicated()]\n",
    "train_duplicates.sort_values(\"Time\")"
   ]
  },
  {
   "source": [
    "It appears we have a number of duplicates in our datasets. Unfortunately, our data does not contain a clearly identifiable primary key such as 'Transaction ID'. If that was the case then we could simply remove duplicates which shared the same transaction ID.\n",
    "\n",
    "Looking at the documentation for the dataset (Source: https://www.kaggle.com/mlg-ulb/creditcardfraud) we can see that V1-V28 were likely to have been anonymised for the sake of protecting user's identity. This means that it is likely that the values in these fields combined could be enough to uniquely identity a person. Therefore, it makes it highly improbable for all the values in V1-28 AS WELL AS the values in time and amount to all be exactly the same in more than one entry. On this basis, it seems sensible to remove the duplicate values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(199364, 31)\n(198779, 31)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate data\n",
    "train_df = train_raw_df.drop_duplicates()\n",
    "test_df = test_raw_df.drop_duplicates()\n",
    "print(train_raw_df.shape)\n",
    "print(train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "199359    0\n",
       "199360    0\n",
       "199361    0\n",
       "199362    0\n",
       "199363    0\n",
       "Name: Class, Length: 199364, dtype: category\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Convert the 'Class' colum from int64 to category as we know it is a categorical variable\n",
    "train_df[\"Class\"] = train_df['Class'].astype('category')\n",
    "train_df[\"Class\"]\n"
   ]
  },
  {
   "source": [
    "## Imbalanced Data - Undersampling vs Oversampling\n",
    "\n",
    "Imbalanced data is when the distribution of classes is uneven, and there is a clear majority and minority class. Undersampling involves removing examples in the majority class to help balance the data, whereas oversampling involves duplicating example from the minority class.  (Source: https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now we should try to identify influencial variables by performing futher exploratory analysis whilst also cleaning up the data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research fraud detection\n",
    "# Do main data cleaning stuff here\n",
    "# Identify influencial variables"
   ]
  },
  {
   "source": [
    "Now we want to visualise the data so we need to perform dimensionality reduction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do dimensonality reduction \n",
    "# Do some good plt plots"
   ]
  },
  {
   "source": [
    "Identify and discuss at least 2 suitable evaluation metrics for this task. Then classify the data.\n",
    "\n",
    "Since we are working with imbalanced data, it does not make sense to use accuracy as an evaluation metric. This is because if the system just predicted everything to be negative (i.e. class = 0) it would still get a high accuracy score. Instead we should look at precision, recall, and the F1 score which is a combination of the previous two. \n",
    "\n",
    "Since we have a low number of overall positive cases (i.e. where the class = 1), recall and F1 score will be the two most important metrics here and therefore what will be taken into account. This is because recall is the number of true positives divided by the total number of actual positives in the dataset. This means it will give a low score if the model gives a lot of false negatives. F1 score is good because it combines both precision and recall to give a good overall score. (Source: https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research what evaluation metrics are good\n",
    "# Learn what it means by classify\n",
    "# Standardise 'Time' and 'Amount'       "
   ]
  },
  {
   "source": [
    "Using a model based method, identify the top 8 most influential variables in the dataset\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a model here to get the top 8 most influential variables"
   ]
  }
 ]
}